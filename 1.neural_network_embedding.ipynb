{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Embedding\n",
    "> [참고](https://keraskorea.github.io/posts/2018-10-16-%EB%89%B4%EB%9F%B4%20%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%20%EC%9E%84%EB%B2%A0%EB%94%A9%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EB%A7%8C%EB%93%A4%EA%B8%B0/)\n",
    "\n",
    "- 유사한 위키피디아 페이지로 연결되는 책들은 서로 비슷하다 > 위키피디아 링크를 기준으로 nearest neighbor을 그룹핑할 수 있다 > 링크 기준으로 유사도 계산\n",
    "- Data: 첵의 제목, 기본정보, 위키링크, 외부 사이트 링크 > 제목+위키링크\n",
    "    - 가장 많이 연결된 위키 페이지: paperback, hardcover 등은 책의 특징을 가리는데 영향을 주지 않는다->제거\n",
    "    - (책 제목, 위키링크)가 주어지면 위키링크가 책의 기사에 존재하는지 확인\n",
    "    - 책 이름에 고유 인덱스 부여\n",
    "    \n",
    "- 위키피디아 링크 = beer의 정보 (score, taste, smell 등)\n",
    "- Data: beerID, beer정보(score,smell 등*확인필요*)\n",
    "- BeerID는 이미 고유 인덱스 형태이므로 변환할 필요가 없다\n",
    "\n",
    "1. input: beerID, score에 대한 병렬 입력\n",
    "2. Embedding: beerID, score를 위한 병렬길이 50개의 임베딩 - 목표의 손실을 최소화하기 위한 신경망의 가중치(weight)\n",
    "3. Dot: 내적을 계산하여 임베딩 합치기\n",
    "4. Reshape: 임베딩 형태를 단일 숫자로\n",
    "5. Dense: 시그모이드 활성화를 위한 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('my_df.csv')\n",
    "data_new = data.drop('user',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.97, 4.04, 3.71, ..., 4.05, 4.04, 4.26])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pairs 대신\n",
    "data2 = data_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_index = data2[:,0]\n",
    "rating = data2[:,1]\n",
    "len(beer_index);len(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 임베딩 모델 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def beer_embedding_model(embedding_size = 50, classification = False):\n",
    "    # input\n",
    "    beer = Input(name = 'beer', shape = [1])\n",
    "    rating = Input(name = 'rating', shape = [1])\n",
    "    \n",
    "    # beer 임베딩\n",
    "    beer_embedding = Embedding(name = 'beer_embedding',input_dim = len(beer_index), output_dim = embedding_size)(beer)\n",
    "    # rating 임베딩\n",
    "    rating_embedding = Embedding(name = 'rating_embedding',input_dim = len(rating),output_dim = embedding_size)(rating)\n",
    "    \n",
    "    # Dot(내적)으로 shape(None,1,1)로 줄이기\n",
    "    merged = Dot(name = 'dot_product', normalize = True, axes = 2)([beer_embedding,rating_embedding])\n",
    "    \n",
    "    # 단일 숫자 shape(None,1)로 줄이기\n",
    "    merged = Reshape(target_shape = [1])(merged)\n",
    "    \n",
    "    # output 출력\n",
    "    out = Dense(1, activation = 'sigmoid')(merged)\n",
    "    model = Model(inputs = [beer,rating], outputs = out)\n",
    "    \n",
    "    #학습 단계\n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', matrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.tolist>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_list = data2.tolist\n",
    "data2_list\n",
    "#data_set = set(data2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(100)\n",
    "\n",
    "def generate_batch(data2, n_positive=50, negative_ratio = 1.0):\n",
    "    # batch 저장용 array\n",
    "    batch_size = n_positive*(1+negative_ratio)\n",
    "    batch = np.zeros((batch_size,3))\n",
    "    \n",
    "    #샘플 준비\n",
    "    while True:\n",
    "        for idx, (beerID,rating_i) in enumerate(random.sample(data2,n_positive)):\n",
    "            batch[idx,:] = (beerID,rating_i,1)\n",
    "        idx += 1\n",
    "        \n",
    "        while idx < batch_size:\n",
    "            random_beer = random.randrange(len(beerID))\n",
    "            random_rating = random.randrange(len(rating))\n",
    "            \n",
    "            if (random_beer,random_rating) not in data2_set:\n",
    "                batch[idx,:] = (random_beer,random_rating,neg_label)\n",
    "                idx += 1\n",
    "                \n",
    "        np.random.shuffle(batch)\n",
    "        yield{'beer':batch[:,0],'rating':batch[:,1]},batch[:,2]              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d35fd6628f1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_postive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnegative_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mn_postive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "n_postive = 1024\n",
    "\n",
    "gen = generate_batch(data2,n_postive,negative_ratio=2)\n",
    "\n",
    "h = model.fit_generator(gen, epoch=15, steps_per_epoch = len(data2)//n_postive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
