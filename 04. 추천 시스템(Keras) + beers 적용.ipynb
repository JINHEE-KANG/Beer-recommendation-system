{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it's debatable whether this topic even qualifies as \"deep learning\" because we're going to see how to build a pretty good recommender system without using a neural network at all! We will, however, take advantage of the power of a modern computation framework like Keras to implement the recommender with minimal code. We'll try a couple different approaches using a technique called collaborative filtering. Finally we'll build a true neural network and see how it compares to the collaborative filtering approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neural network(신경망) 같은 딥러닝을 쓰지 않아도 꽤 좋은 추천 시스템을 만들 수 있다. 그렇다면, 딥러닝은 왜 쓰는가?\n",
    "- 더 코드가 단순하다!\n",
    "- 더 많은 데이터를 사용할 수 있다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering(CF)\n",
    "- 전처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://www.johnwittenauer.net/deep-learning-with-keras-recommender-systems/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>username</th>\n",
       "      <th>look</th>\n",
       "      <th>smell</th>\n",
       "      <th>taste</th>\n",
       "      <th>feel</th>\n",
       "      <th>overall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271781</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9449</td>\n",
       "      <td>78043</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10982</td>\n",
       "      <td>225791</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17441</td>\n",
       "      <td>77030</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18672</td>\n",
       "      <td>47658</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  beer_id      username  look  smell  taste  feel  overall  score\n",
       "0           0   271781  bluejacket74  4.00   4.00    4.0  4.25     4.00   4.03\n",
       "1        9449    78043  bluejacket74  3.50   4.00    3.5  3.50     3.50   3.62\n",
       "2       10982   225791  bluejacket74  4.25   4.00    4.0  3.75     4.00   3.99\n",
       "3       17441    77030  bluejacket74  3.50   3.75    4.0  3.75     3.75   3.84\n",
       "4       18672    47658  bluejacket74  4.50   5.00    5.0  5.00     5.00   4.97"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv( 'new_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4403885, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) #중간발표 때 1차 전처리를 했던 440만개의 데이터를 활용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#잠깐 전처리\n",
    "\n",
    "cols = ['beer_id','username','score']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beerid</th>\n",
       "      <th>userid</th>\n",
       "      <th>rating</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>271781</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>78043</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>225791</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>77030</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>47658</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beerid        userid  rating userId\n",
       "0  271781  bluejacket74    4.03      0\n",
       "1   78043  bluejacket74    3.62      0\n",
       "2  225791  bluejacket74    3.99      0\n",
       "3   77030  bluejacket74    3.84      0\n",
       "4   47658  bluejacket74    4.97      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {'beer_id':'beerid','username':'userid','score':'rating'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>beerid</th>\n",
       "      <th>88</th>\n",
       "      <th>276</th>\n",
       "      <th>412</th>\n",
       "      <th>1093</th>\n",
       "      <th>1708</th>\n",
       "      <th>1904</th>\n",
       "      <th>2093</th>\n",
       "      <th>7971</th>\n",
       "      <th>10672</th>\n",
       "      <th>11757</th>\n",
       "      <th>17112</th>\n",
       "      <th>19960</th>\n",
       "      <th>29619</th>\n",
       "      <th>34483</th>\n",
       "      <th>89174</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Knapp85</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sammy</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>StonedTrippin</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UCLABrewN84</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.03</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acurtis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>biboergosum</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>brentk56</td>\n",
       "      <td>4.23</td>\n",
       "      <td>3.79</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emerge077</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jaydoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kojevergas</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kylehay2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.62</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metter98</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>superspak</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>zeff80</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "beerid         88     276    412    1093   1708   1904   2093   7971   10672  \\\n",
       "userid                                                                         \n",
       "BEERchitect     4.28   4.42   4.45   4.55   4.80   4.18   4.27   4.55   4.82   \n",
       "Knapp85         4.00   3.68   4.53   4.27   4.47   3.75   4.45   4.65   4.17   \n",
       "Sammy           3.80   3.75   3.83   4.30   4.20   4.08   4.05   4.15   4.23   \n",
       "StonedTrippin   4.30   3.72   3.70   4.32   4.32   4.21   4.25   4.52   4.42   \n",
       "UCLABrewN84     4.23   4.20   4.48   4.17   4.47   3.72   3.03   4.95   4.77   \n",
       "acurtis          NaN    NaN    NaN    NaN    NaN    NaN    NaN   4.10    NaN   \n",
       "biboergosum     4.42   4.12   4.15   3.95   4.30   4.03   4.23   4.27   4.19   \n",
       "brentk56        4.23   3.79   4.13   4.50   4.53   4.27   4.82   4.46   4.45   \n",
       "emerge077       4.15    NaN    NaN   4.33   4.42   4.28   3.83   4.30   4.60   \n",
       "jaydoc           NaN    NaN   4.29   4.19    NaN    NaN   4.38   4.53   4.51   \n",
       "kojevergas      2.62   3.40   3.68   3.44   3.60   3.53   3.33   3.72   3.95   \n",
       "kylehay2004      NaN   3.90   4.42   4.62   3.40   4.23   4.58   4.97   4.72   \n",
       "metter98        4.22   3.88   4.33   4.23   4.38   4.20   4.20   4.42   4.34   \n",
       "superspak       4.33   4.10   4.36   4.20   4.42   4.13   4.20   4.20   4.62   \n",
       "zeff80          4.57   4.25   4.50   4.20   4.52   4.25   4.62   4.84   4.85   \n",
       "\n",
       "beerid         11757  17112  19960  29619  34483  89174  \n",
       "userid                                                   \n",
       "BEERchitect     4.45   4.63   4.84   4.34   4.23   4.27  \n",
       "Knapp85         4.50   4.57   4.67   4.42   4.35   4.27  \n",
       "Sammy           4.27   3.80   4.00   4.22   4.18   3.73  \n",
       "StonedTrippin   4.10   4.09   4.54   4.48   4.18   4.30  \n",
       "UCLABrewN84     4.45   4.39   4.74   4.21   4.50   3.89  \n",
       "acurtis          NaN    NaN    NaN   4.09    NaN   3.85  \n",
       "biboergosum     4.15   4.00   4.33   4.13   4.34   4.36  \n",
       "brentk56        4.85   4.47   4.21   4.50   4.38   4.40  \n",
       "emerge077       4.33   4.33   4.42   4.30   4.33   4.13  \n",
       "jaydoc          4.44   4.12   4.50   4.29   4.44   4.06  \n",
       "kojevergas      4.00   4.03   4.09   3.92   3.54   3.48  \n",
       "kylehay2004     4.65   4.95   4.64   4.15   4.62    NaN  \n",
       "metter98        4.45   4.45   4.40   4.47   4.33   4.13  \n",
       "superspak       4.47   4.30   4.38   4.33   4.20   4.32  \n",
       "zeff80          4.45   4.87   4.45   4.57   4.50   4.54  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 15 users, top 15 movies -> table\n",
    "\n",
    "g = df.groupby('userid')['rating'].count() #유저아이디별로, rating을 몇 개를 주었는가?\n",
    "top_users = g.sort_values(ascending=False)[:15] #rating을 많이 한 유저 상위 15명\n",
    "\n",
    "g = df.groupby('beerid')['rating'].count() #beer아이디별로, rating은 몇 개인가?\n",
    "top_beers = g.sort_values(ascending=False)[:15] #rating이 많은 상위 맥주 15개\n",
    "\n",
    "top_r = df.join(top_users, rsuffix='_r', how='inner', on='userid') #ratings df에 top_users join\n",
    "top_r = top_r.join(top_beers, rsuffix='_r', how='inner', on='beerid') #위에서 만든 df에 top_movies join\n",
    "\n",
    "pd.crosstab(top_r.userid, top_r.beerid, top_r.rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder\n",
    "- user/beer 컬럼은 지금은 non-sequentail integer이다. 그러므로 unique ID를 나타내는 것으로 value를 바꿔주어야 한다.\n",
    "- 이 때 이용하는 것이 바로 'labelencoder()' <-발표자료에는 이것의 설명도 추가.(캡처확인)\n",
    "- 이를 이용하면 모델링을 위해, 변수의 value를 0부터 시작되는 숫자로 바꿀 수 있다. (숫자->숫자도 되고 문자->숫자도 된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9012, 154711, 1.0, 5.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#딥러닝에 이용할 컬럼 변경: user, beer, rating\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "df['user'] = user_enc.fit_transform(df['userid'].values)\n",
    "n_users = df['user'].nunique()\n",
    "\n",
    "item_enc = LabelEncoder()\n",
    "df['beer'] = item_enc.fit_transform(df['beerid'].values)\n",
    "n_beers = df['beer'].nunique()\n",
    "\n",
    "df['rating'] = df['rating'].values.astype(np.float32)\n",
    "min_rating = min(df['rating'])\n",
    "max_rating = max(df['rating'])\n",
    "\n",
    "n_users, n_beers, min_rating, max_rating #n_users, n_beers: 유니크한 값 개수, rating의 최솟값과 최댓값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beerid</th>\n",
       "      <th>userid</th>\n",
       "      <th>rating</th>\n",
       "      <th>userId</th>\n",
       "      <th>user</th>\n",
       "      <th>beer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>271781</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0</td>\n",
       "      <td>5227</td>\n",
       "      <td>129595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>78043</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0</td>\n",
       "      <td>5227</td>\n",
       "      <td>43239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>225791</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "      <td>5227</td>\n",
       "      <td>112870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>77030</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0</td>\n",
       "      <td>5227</td>\n",
       "      <td>42548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>47658</td>\n",
       "      <td>bluejacket74</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>5227</td>\n",
       "      <td>24908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beerid        userid  rating userId  user    beer\n",
       "0  271781  bluejacket74    4.03      0  5227  129595\n",
       "1   78043  bluejacket74    3.62      0  5227   43239\n",
       "2  225791  bluejacket74    3.99      0  5227  112870\n",
       "3   77030  bluejacket74    3.84      0  5227   42548\n",
       "4   47658  bluejacket74    4.97      0  5227   24908"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #완료된 데이터셋. 여기서 'user','beer','rating'만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3082719, 2), (1321166, 2), (3082719,), (1321166,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train, test 셋 분할: test size는 0.3, random_state는 임의로 지정\n",
    "\n",
    "X = df[['user', 'beer']].values\n",
    "y = df['rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 모델을 만들 때 필요한 또다른 변수는: 잠재요인의 개수를 정하는 것!\n",
    "#잠재요인의 개수는 원하는 대로 설정하면 되지만, 주의할 것은 user와 beer 모두에 대해 같은 사이즈를 줘야 한다는 점.\n",
    "\n",
    "#우리는 50개로 간다!(X에 대해서만 적용)\n",
    "n_factors = 50\n",
    "\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras 라이브러리 로드\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Dot\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommdation System using Keras \n",
    "- 각 유저와 각 맥주를 나타내기 위해 'embedding'이라는 것을 활용한다.->(설명부분 캡처)\n",
    "- 'embeddings'는 벡터이다(n_factor 사이즈의). 시작은 랜덤한 숫자로 가고, 각 유저/맥주의 필수적인 특징을 잡으면 fit model을 해보자.\n",
    "- fit model 과정) 유저 벡터와 맥주 벡터를 스칼라곱(dot product)하여 예측 평점을 계산함.\n",
    "- 이를 위해선 유니크한 유저 수와 맥주 수가 필요, -> 각각의 embedding matrix의 사이즈를 정의하기 위함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we get to the model itself. The main idea here is we're going to use embeddings to represent each user and each movie in the data. These embeddings will be vectors (of size n_factors) that start out as random numbers but are fit by the model to capture the essential qualities of each user/movie. We can accomplish this by computing the dot product between a user vector and a movie vector to get a predicted rating. The code is fairly simple, there isn't even a traditional neural network layer or activation involved. I stuck some regularization on the embedding layers and used a different initializer but even that probably isn't necessary. Notice that this is where we need the number of unique users and movies, since those are required to define the size of each embedding matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecommenderV1 함수\n",
    "- input : n_users(# of unique users), n_beers(# of uniuqe beers), n_factors(잠재요인 수)\n",
    "- 이 함수를 사용하면 예측평점 계산하기가 아주 간편하다.(역시 계산이 간단한 딥러닝^-^)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고(케라스 사전: embedding): https://keras.io/layers/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecommenderV1(n_users, n_beers, n_factors):\n",
    "    user = Input(shape=(1,))\n",
    "    u = Embedding(n_users, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(user)\n",
    "    #embedding initializer로는 he_normal 사용: normal dist'n\n",
    "    #embeddings_regularizer로는 \n",
    "    u = Reshape((n_factors,))(u)\n",
    "    \n",
    "    beer = Input(shape=(1,))\n",
    "    m = Embedding(n_beers, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(beer)\n",
    "    m = Reshape((n_factors,))(m)\n",
    "    \n",
    "    x = Dot(axes=1)([u, m])\n",
    "\n",
    "    model = Model(inputs=[user, beer], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 50)        450600      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 50)        7735550     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 50)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 50)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 1)            0           reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,186,150\n",
      "Trainable params: 8,186,150\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderV1(n_users, n_beers, n_factors)\n",
    "model.summary()\n",
    "\n",
    "#Below you can see that all of the parameters are in the embedding layers, \n",
    "#we don't have any traditional neural net components at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 train셋에 학습\n",
    "<주요 인자> model.fit(x, y, batch_size=32, epochs=10)\n",
    "- x: 입력 데이터\n",
    "- y: 라벨 값\n",
    "- batch_size : 몇 개의 샘플로 가중치를 갱신할 것인지 지정 (작을수록 가중치 갱신이 자주 일어남, 더 업데이트를 많이 하게 됨.)\n",
    "- epochs : 학습 반복의 횟수 (클수록 학습을 많이 하므로 정확도가 높아지지만, 너무 크면 과적합의 가능성)\n",
    "- 참고) https://tykimos.github.io/2017/03/25/Fit_Talk/ 설명 잘나와있음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3082719 samples, validate on 1321166 samples\n",
      "Epoch 1/5\n",
      "3082719/3082719 [==============================] - 68s 22us/step - loss: 11.4058 - val_loss: 4.0669\n",
      "Epoch 2/5\n",
      "3082719/3082719 [==============================] - 57s 18us/step - loss: 2.3264 - val_loss: 1.5333\n",
      "Epoch 3/5\n",
      "3082719/3082719 [==============================] - 58s 19us/step - loss: 1.0717 - val_loss: 0.9651\n",
      "Epoch 4/5\n",
      "3082719/3082719 [==============================] - 83s 27us/step - loss: 0.6941 - val_loss: 0.7404\n",
      "Epoch 5/5\n",
      "3082719/3082719 [==============================] - 71s 23us/step - loss: 0.5389 - val_loss: 0.6342\n"
     ]
    }
   ],
   "source": [
    "#우리의 X_train의 개수는 308만개, X_test의 개수는 132만개이므로 만개를 batch_size로 설정함.\n",
    "hist1 = model.fit(x=X_train_array, y=y_train, batch_size=10000, epochs=5,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecommenderV2 함수\n",
    "- 각각의 embedding에 'bias'를 추가해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I also refactored the code a bit by pulling out the embedding layer \n",
    "# and reshape operation into a separate class.\n",
    "\n",
    "from keras.layers import Add, Activation, Lambda\n",
    "\n",
    "class EmbeddingLayer:\n",
    "    def __init__(self, n_items, n_factors):\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(x)\n",
    "        x = Reshape((self.n_factors,))(x)\n",
    "        return x\n",
    "\n",
    "def RecommenderV2(n_users, n_beers, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    ub = EmbeddingLayer(n_users, 1)(user)\n",
    "    \n",
    "    beer = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_beers, n_factors)(beer)\n",
    "    mb = EmbeddingLayer(n_beers, 1)(beer)\n",
    "\n",
    "    x = Dot(axes=1)([u, m])\n",
    "    x = Add()([x, ub, mb])\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "\n",
    "    model = Model(inputs=[user, beer], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 50)        450600      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 50)        7735550     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 50)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 50)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 1)         9012        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 1)         154711      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 1)            0           reshape_9[0][0]                  \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1)            0           dot_4[0][0]                      \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 8,349,873\n",
      "Trainable params: 8,349,873\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderV2(n_users, n_beers, n_factors, min_rating, max_rating)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3082719 samples, validate on 1321166 samples\n",
      "Epoch 1/5\n",
      "3082719/3082719 [==============================] - 93s 30us/step - loss: 0.6064 - val_loss: 0.2325\n",
      "Epoch 2/5\n",
      "3082719/3082719 [==============================] - 76s 25us/step - loss: 0.1977 - val_loss: 0.1863\n",
      "Epoch 3/5\n",
      "3082719/3082719 [==============================] - 85s 28us/step - loss: 0.1740 - val_loss: 0.1781\n",
      "Epoch 4/5\n",
      "3082719/3082719 [==============================] - 69s 22us/step - loss: 0.1672 - val_loss: 0.1746\n",
      "Epoch 5/5\n",
      "3082719/3082719 [==============================] - 68s 22us/step - loss: 0.1632 - val_loss: 0.1721\n"
     ]
    }
   ],
   "source": [
    "hist2 = model.fit(x=X_train_array, y=y_train, batch_size=10000, epochs=5,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 학습과정 살펴보기\n",
    "- 참고) https://tykimos.github.io/2017/07/09/Training_Monitoring/\n",
    "- https://snowdeer.github.io/machine-learning/2018/01/11/keras-use-history-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1321166/1321166 [==============================] - 4s 3us/step\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-d4196ca1b2c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuray : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_array, y_test, batch_size =10000)\n",
    "score\n",
    "#print('')\n",
    "#print('loss : ' + str(score[0]))\n",
    "#print('accuray : ' + str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = hist2.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist2.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist2.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist2.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist2.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecommenderNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate, Dense, Dropout\n",
    "\n",
    "def RecommenderNet(n_users, n_beers, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    \n",
    "    beer = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_beers, n_factors)(beer)\n",
    "    \n",
    "    x = Concatenate()([u, m])\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "\n",
    "    model = Model(inputs=[user, beer], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 50)        450600      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 50)        7735550     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 50)           0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 50)           0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100)          0           reshape_14[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1010        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            11          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 8,187,171\n",
      "Trainable params: 8,187,171\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderNet(n_users, n_beers, n_factors, min_rating, max_rating)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3082719 samples, validate on 1321166 samples\n",
      "Epoch 1/5\n",
      "3082719/3082719 [==============================] - 176s 57us/step - loss: 0.1621 - val_loss: 0.1394\n",
      "Epoch 2/5\n",
      "3082719/3082719 [==============================] - 125s 40us/step - loss: 0.1572 - val_loss: 0.1395\n",
      "Epoch 3/5\n",
      "1695000/3082719 [===============>..............] - ETA: 56s - loss: 0.1544"
     ]
    }
   ],
   "source": [
    "hist3 = model.fit(x=X_train_array, y=y_train, batch_size=5000, epochs=5,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = hist3.history\n",
    "history_dict.keys() #근데 왜 acc가 없을까?\n",
    "#history_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1321166/1321166 [==============================] - 4s 3us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13701472737170253"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test_array, y_test, batch_size =5000)\n",
    "score\n",
    "\n",
    "#10000으로 했을 때의 score : 0.13701472737170253\n",
    "#5000으로 했을 때의 score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-593cb660f0e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist3.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist3.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist3.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist3.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 결과 비교\n",
    "\n",
    "pred = pd.DataFrame(model.predict(X_test_array, batch_size=10000), columns=['pred'])\n",
    "actual = pd.DataFrame(y_test, columns=['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.194257</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.518090</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.592885</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.752315</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.806270</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred  actual\n",
       "0  4.194257    4.22\n",
       "1  3.518090    2.59\n",
       "2  3.592885    3.63\n",
       "3  3.752315    3.68\n",
       "4  3.806270    3.97"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat( [pred, actual], axis = 1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.194257</td>\n",
       "      <td>4.22</td>\n",
       "      <td>-0.025743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.518090</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.928090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.592885</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.752315</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.072315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.806270</td>\n",
       "      <td>3.97</td>\n",
       "      <td>-0.163730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.210329</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.190329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.054770</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.054770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.503155</td>\n",
       "      <td>3.71</td>\n",
       "      <td>-0.206845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.824488</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.175512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.159501</td>\n",
       "      <td>3.28</td>\n",
       "      <td>-0.120499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.066195</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.066195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.051651</td>\n",
       "      <td>4.32</td>\n",
       "      <td>-0.268349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.791037</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.021037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.172848</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.052848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.016800</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-0.083200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred  actual      diff\n",
       "0   4.194257    4.22 -0.025743\n",
       "1   3.518090    2.59  0.928090\n",
       "2   3.592885    3.63 -0.037115\n",
       "3   3.752315    3.68  0.072315\n",
       "4   3.806270    3.97 -0.163730\n",
       "5   4.210329    4.02  0.190329\n",
       "6   4.054770    4.00  0.054770\n",
       "7   3.503155    3.71 -0.206845\n",
       "8   3.824488    4.00 -0.175512\n",
       "9   3.159501    3.28 -0.120499\n",
       "10  4.066195    4.00  0.066195\n",
       "11  4.051651    4.32 -0.268349\n",
       "12  3.791037    3.77  0.021037\n",
       "13  4.172848    4.12  0.052848\n",
       "14  4.016800    4.10 -0.083200"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['diff'] = result['pred'] - result['actual']\n",
    "\n",
    "result.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.013670957"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(result['diff'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c9fb865848>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result['diff'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic : -43.197 \n",
      "p-value : 0.000\n"
     ]
    }
   ],
   "source": [
    "#일표본 t-검정 #0으로 볼 수는 없음\n",
    "from scipy import stats\n",
    "diff = result['diff']  \n",
    "res= stats.ttest_1samp(diff, 0) \n",
    "print('t statistic : %.3f \\np-value : %.3f' % (res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
